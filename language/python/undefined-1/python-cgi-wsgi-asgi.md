# 웹 서버는 어떻게 Python 코드를 실행하게 되었는가 — CGI, WSGI, ASGI의 발전과 실전 배포 (비동기 코루틴 작업 정리 필요)

#### 들어가며: 웹 서버는 Python을 모른다

Nginx나 Apache 같은 웹 서버는 HTML, CSS, 이미지 같은 정적 파일을 클라이언트에게 전달하는 데 특화되어 있다. 하지만 "이 사용자의 장바구니를 조회해서 보여줘"와 같은 동적인 요청은 웹 서버 혼자 처리할 수 없다. Python 코드를 실행해야 하기 때문이다.

문제는, 웹 서버는 Python을 모른다는 것이다. 그래서 웹 서버와 Python 애플리케이션 사이에 "이런 형식으로 요청을 넘기고, 이런 형식으로 응답을 받자"는 약속이 필요하다. 이 약속이 바로 CGI, WSGI, ASGI이며, 각각은 이전 방식의 한계를 극복하기 위해 등장했다.

***

#### 1장. 시작 — CGI: 요청이 올 때마다 프로그램을 새로 실행하다

**CGI(Common Gateway Interface)**&#xB294; 웹 서버와 외부 프로그램을 연결시켜주는 가장 초기 형태의 표준화된 인터페이스 규약이다.

동작 방식은 단순하다. 클라이언트 요청이 올 때마다 **새로운 프로세스를 생성하여** Python 프로그램을 실행하고, 응답을 반환하면 프로세스를 종료한다.

문제는 명확했다. 요청마다 프로세스를 만들고 없애는 작업을 반복하므로 오버헤드가 매우 크고, 다량의 요청이 들어오면 서버 리소스가 쉽게 고갈된다. 웹이 단순한 문서 조회 수준이던 시절에는 괜찮았지만, 트래픽이 늘어나면서 근본적인 한계에 부딪혔다.

> **핵심 문제: 매 요청마다 프로세스를 생성하고 삭제하는 비용이 너무 크다.**

***

#### 2장. 발전 — WSGI: 프로세스를 재사용하여 효율을 높이다

CGI의 문제를 해결하기 위해 **WSGI(Web Server Gateway Interface, PEP 3333)**&#xAC00; 등장했다. 동기적인 Python 웹 애플리케이션을 위해 설계된 표준 인터페이스이다.

WSGI의 핵심 개선은 단순하다. 매번 프로세스를 만드는 대신, **프로세스 풀 형태로 워커를 미리 생성해두고 재사용**하는 것이다. 요청이 오면 이미 떠 있는 워커가 처리하고, 끝나면 죽지 않고 다음 요청을 기다린다.

다만 WSGI는 기본적으로 **동기 처리(Blocking)** 방식이다. 요청이 들어오면 해당 요청이 완전히 끝날 때까지 워커가 다른 요청을 처리하지 못한다. 일반적인 HTTP 요청은 수십\~수백 ms면 끝나므로 문제가 없지만, 웹소켓처럼 연결을 오래 유지해야 하는 실시간 통신에서는 워커 하나가 연결 하나에 묶여버린다. 동시 접속자가 100명이면 워커 100개가 필요하고, 이는 비현실적이다.

**프레임워크**: Flask, Django 등이 대표적. Django는 3.0부터 ASGI도 지원하지만, 여전히 WSGI로 운영하는 경우가 많다.

**구현체 비교: Gunicorn vs uWSGI**

WSGI 스펙을 구현한 서버는 여러 가지인데, 가장 대표적인 두 가지를 비교한다.

**주요 성능 차이**

* **처리량 및 안정성**: Gunicorn은 에러 발생률이 낮고 안정적인 성능을 보인다. uWSGI는 설정이 복잡한 만큼 튜닝이 잘 되면 높은 처리량을 낼 수 있지만, 기본 설정에서는 상대적으로 높은 응답 지연을 보이는 경우가 있다.
* **자원 효율성**: uWSGI는 내장 기능이 많은 만큼 프로세스 자체가 무거워, 워커당 메모리 사용량이 Gunicorn보다 높은 편이다.
* **작업 모델**: 둘 다 기본적으로 pre-fork 모델(마스터 프로세스가 워커 프로세스를 관리)을 사용한다. 다만 Gunicorn은 gevent/uvicorn 워커를, uWSGI는 자체 async 모드를 통해 각각 비동기 처리도 지원한다.

**Gunicorn의 장단점**

장점:

* 높은 안정성: 에러가 적고 견고하여 동기식 Python 웹 배포의 사실상 표준
* 단순한 운영: 설정이 쉽고, 워커 충돌 시 자동 재시작 등 프로세스 관리가 뛰어남
* 유연한 확장: Uvicorn을 워커로 사용하는 방식으로 ASGI 앱도 운영 가능

단점:

* 기본 동기식 워커로는 웹소켓, 실시간 통신에 부적합 (Uvicorn 워커 병행으로 해소 가능)
* 서버 수준의 캐싱, 크론 등 부가 기능이 없어 별도 도구가 필요

**uWSGI의 장단점**

장점:

* 올인원 플랫폼: 내장 캐싱, 크론 스케줄러, 로드밸런싱, 프로세스 자동 관리(Emperor 모드) 등 인프라 수준의 기능을 자체 제공
* Nginx 최적화 연동: 자체 uwsgi 프로토콜로 Nginx와 통신하면 HTTP 파싱 오버헤드를 줄일 수 있음
* 범용성: Python 외에 Ruby, PHP 등 다중 언어 지원

단점:

* 높은 복잡도: 설정 옵션이 수백 개에 달하며, 잘못된 설정이 오히려 성능 저하를 유발
* 높은 메모리 사용: 내장 기능이 많아 워커 프로세스가 무거움
* 유지보수 우려: 최근 개발이 활발하지 않아 커뮤니티 지원이 줄어드는 추세

> **WSGI가 해결한 것: 프로세스 재사용으로 CGI의 오버헤드 문제를 해결했다.** \
> **WSGI가 해결하지 못한 것: 동기 방식의 한계로 웹소켓, 실시간 통신, 대량 동시 연결 처리가 어렵다.**

***

#### 3장. 전환 — ASGI: 비동기로 동시성의 벽을 넘다

웹소켓, 실시간 알림, 대량의 동시 연결 등 현대 웹의 요구사항이 늘어나면서, WSGI의 동기 모델로는 감당이 어려워졌다. 이를 해결하기 위해 **ASGI(Asynchronous Server Gateway Interface)**&#xAC00; 등장했다. WSGI의 한계를 보완하여 비동기 처리가 가능하도록 설계된 현대적인 후속 인터페이스이다.

**특징**

* **비동기 논블로킹**: async/await 구문을 사용하여 한 번에 많은 수의 동시 요청을 효과적으로 처리할 수 있다. I/O 대기 중에 다른 요청을 처리하므로, 단일 프로세스에서도 수천 개의 동시 연결이 가능하다.
* **프로토콜의 다양성**: 비동기 설계 덕분에 HTTP뿐 아니라 웹소켓, HTTP/2, HTTP/3 같은 프로토콜을 지원하기에 유리하다. 다만 실제 지원 여부는 구현체(Uvicorn, Daphne, Hypercorn 등)에 따라 다르다.
* **확장성**: 대용량 트래픽이나 실시간 데이터 스트리밍이 필요한 현대적인 앱에 적합하다.

**프레임워크**: FastAPI, Starlette, Django(3.0 이후 ASGI 지원) 등이 대표적

**구현체 비교: Uvicorn vs Daphne**

**1. 성능 및 자원 효율성**

여러 벤치마크에서 Uvicorn이 Daphne 대비 더 높은 초당 요청 처리수(RPS)와 더 낮은 메모리 사용량을 보이는 경향이 있다. 이는 Uvicorn이 uvloop과 httptools라는 C 기반 고성능 라이브러리를 활용하기 때문이다. 다만 구체적인 수치는 워크로드와 설정에 따라 달라지므로, 자신의 환경에서 직접 테스트해보는 것이 바람직하다.

**2. 지원 프로토콜**

* Uvicorn: HTTP/1.1과 WebSocket을 지원한다. HTTP/2는 공식적으로 지원하지 않는다.
* Daphne: HTTP/1.1, HTTP/2, WebSocket을 지원한다.

다만 실제 프로덕션에서는 Nginx 등 리버스 프록시가 클라이언트와 HTTP/2로 통신하고, 백엔드로는 HTTP/1.1로 전달하는 구성이 일반적이므로, 이 차이가 실질적 영향을 주는 경우는 제한적이다. 만약 앱 서버 레벨에서의 HTTP/2 지원이 필요하다면 Daphne 외에 Hypercorn(HTTP/3까지 지원)도 선택지가 된다.

**3. 확장성**

* Uvicorn: `--workers N` 옵션으로 자체 멀티 프로세스를 지원하며, Gunicorn 워커로도 운영 가능하여 확장이 용이하다.
* Daphne: 자체 멀티 워커 기능이 없어, 확장하려면 별도의 프로세스 관리자나 로드 밸런서를 통해 여러 인스턴스를 운영해야 한다.

**4. 개발 배경 및 생태계**

* Uvicorn: 속도에 최적화된 범용 ASGI 서버로, FastAPI를 비롯한 다양한 ASGI 프레임워크와 함께 사용된다.
* Daphne: Django Channels 프로젝트에서 탄생한 최초의 ASGI 구현체 중 하나로, Django 생태계와 네이티브하게 통합되어 있다.

**요약**: 범용 고성능 ASGI 서버가 필요하다면 Uvicorn이 일반적인 선택이고, Django Channels 기반 실시간 애플리케이션을 구축한다면 Daphne이 자연스러운 선택이다. 앱 서버 레벨에서 HTTP/2 이상의 프로토콜이 필요하다면 Daphne 또는 Hypercorn을 검토할 수 있다.

**Gunicorn과 Uvicorn을 함께 사용하는 이유**

Uvicorn은 매우 빠른 ASGI 서버이지만, 단일 프로세스이므로 CPU 코어를 하나만 활용할 수 있다. CPU 집약적 작업이 이벤트 루프를 블로킹하면 전체 성능이 저하될 수 있다.

Gunicorn은 이 한계를 보완하는 프로세스 관리자 역할을 수행한다. 두 서버를 함께 사용하면 다음과 같은 이점을 얻는다.

* **멀티 프로세스 환경 구성**: Gunicorn이 마스터 프로세스로서 여러 개의 Uvicorn 워커 프로세스를 생성·관리하여, 멀티 코어 CPU를 활용한 병렬 처리가 가능해진다.
* **안정성 및 관리 효율**: 워커 프로세스 충돌 시 자동 재시작, 정상 종료(graceful shutdown) 관리 등 프로덕션 환경에 필요한 견고한 프로세스 관리 기능을 제공한다.
* **워커 수 설정**: 일반적으로 동기 워커 기준 (2 × CPU 코어 수) + 1이 권장되나, Uvicorn처럼 비동기 워커는 워커 하나가 많은 동시 연결을 처리할 수 있으므로 코어 수와 동일하거나 그보다 적게 설정하는 것이 일반적이다. 실제 최적값은 애플리케이션 특성에 따라 부하 테스트로 결정하는 것이 바람직하다.

***

#### 4장. 결론 — 실전 배포: Nginx와 함께 어떤 구성을 선택할 것인가

지금까지 CGI의 한계에서 출발하여 WSGI의 프로세스 재사용, ASGI의 비동기 처리까지 발전 흐름을 살펴보았다. 마지막으로 이 모든 것이 실제 프로덕션 환경에서 어떻게 조합되는지를 정리한다.

클라이언트와 Python 앱 서버 사이에 Nginx를 리버스 프록시로 두는 것이 프로덕션 환경의 기본 구성이다. Nginx는 정적 파일 서빙, SSL 처리, 요청 버퍼링, Rate Limiting 등을 담당하여 Python 앱 서버의 부하를 줄이고 보안을 강화한다. 특히 느린 클라이언트의 요청을 Nginx가 먼저 버퍼링한 뒤 앱 서버에 전달하므로, 워커가 느린 클라이언트에 묶이는 문제를 방지할 수 있다.

**비동기(ASGI) 애플리케이션 (FastAPI, 최신 Django 등)**: Nginx 뒤에 Uvicorn을 배치하는 구성이 가장 일반적이다. Nginx와 Uvicorn은 HTTP로 통신하며, 웹소켓이 필요한 경우 Nginx에 Connection Upgrade 설정을 추가하면 된다.

* **전통적 서버 환경**: Nginx → Gunicorn(프로세스 관리자) + Uvicorn 워커 구성이 안정적이다. Gunicorn이 워커 충돌 시 자동 재시작, 정상 종료 등을 관리한다.
* **컨테이너 환경 (Docker, K8s)**: 컨테이너 오케스트레이터가 프로세스 관리를 대신하므로, Nginx → Uvicorn 단독(`uvicorn --workers N`)으로도 충분한 경우가 많다.

**전통적인 동기(WSGI) 애플리케이션 (Flask, 기존 Django)**: Nginx → Gunicorn 구성이 가장 단순하고 검증된 선택이다. 둘 사이는 HTTP로 통신하며, 설정이 간단하고 안정성이 높아 수년간 표준 구성으로 자리잡았다.

**uWSGI를 사용하는 경우**: Nginx → uWSGI 구성에서는 HTTP 대신 자체 바이너리 프로토콜(uwsgi)로 통신할 수 있다. Nginx가 이 프로토콜을 네이티브로 지원하므로 HTTP 파싱 오버헤드를 줄일 수 있다는 이점이 있다. 내장 캐싱, 크론, Emperor 모드 등 인프라 수준의 기능이 필요하거나 이미 uWSGI 기반으로 운영 중인 환경이라면 유효한 선택이다. 다만 신규 프로젝트에서는 Gunicorn이나 Uvicorn이 더 간결한 선택지이다.

#### 마치며

웹 서버가 Python 코드를 실행하기 위한 인터페이스는 CGI → WSGI → ASGI로 발전해왔다. CGI는 매 요청마다 프로세스를 생성하는 비효율을 안고 있었고, WSGI는 프로세스 재사용으로 이를 해결했지만 동기 방식의 한계가 남았다. ASGI는 비동기 처리를 통해 웹소켓과 대량 동시 연결이라는 현대 웹의 요구까지 수용했다. 그리고 이 모든 구성의 앞단에는 Nginx가 리버스 프록시로서 정적 파일, SSL, 버퍼링을 담당하며 Python 앱 서버를 보호하고 있다. 결국 어떤 구성을 선택하느냐는 애플리케이션의 동기/비동기 여부와 인프라 환경에 따라 결정하면 된다.
