# Python 개발자를 위한 프로세스, 스레드, 그리고 동시성 이해하기

### 들어가며

이 글은 Python 개발자가 알아야 할 프로세스와 스레드의 핵심 개념을 정리한다. 프로세스/스레드의 컨텍스트 스위칭이 OS 수준에서 어떻게 동작하는지부터, Python이 스레드를 어떻게 다루는지, 그리고 GIL의 제약을 넘어 비동기 처리까지 어떻게 발전해왔는지를 다룬다.

***

### 1. 프로세스와 스레드의 컨텍스트 스위칭

컨텍스트 스위칭은 CPU가 여러 작업을 동시에 처리하기 위해 반드시 필요한 작업이다. "컨텍스트 스위칭은 안 할수록 좋다"는 단순한 결론보다는, 각 컨텍스트 스위칭에서 어떤 일이 일어나는지를 이해하는 것이 중요하다.

이 장에서는 OS 수준의 개념이 여러 개 등장하므로, 먼저 핵심 용어를 정리하고 시작한다.

#### 용어 정리

**가상 주소 공간(Virtual Address Space)**: 각 프로세스가 "나만 메모리 전체를 쓰고 있다"고 착각하게 만드는 구조이다. 실제 물리 메모리(RAM)의 주소를 직접 사용하는 것이 아니라, OS가 각 프로세스에게 가짜(가상) 주소를 부여한다. 덕분에 프로세스 A와 B가 같은 주소 `0x1000`을 사용해도 실제로는 RAM의 서로 다른 위치를 가리키게 되어 충돌이 나지 않는다.

**페이지 테이블(Page Table)**: 가상 주소를 실제 물리 주소로 변환하기 위한 "변환표"이다. "가상 주소 0x1000 → 물리 주소 0x5A00"처럼 매핑 정보가 담겨 있다. 각 프로세스마다 자신만의 페이지 테이블을 가진다.

**MMU(Memory Management Unit)**: CPU 안에 있는 하드웨어 장치로, 가상 주소를 물리 주소로 변환하는 작업을 실제로 수행한다. CPU가 가상 주소로 메모리에 접근하려 할 때, MMU가 페이지 테이블을 참조하여 실제 RAM 주소를 찾아준다.

**TLB(Translation Lookaside Buffer)**: MMU 안에 있는 작은 캐시이다. 페이지 테이블은 메인 메모리(RAM)에 있어서 매번 조회하면 느리다. 그래서 최근에 변환한 "가상 주소 → 물리 주소" 결과를 TLB에 캐싱해두고, 같은 주소 변환 요청이 오면 RAM까지 가지 않고 TLB에서 바로 꺼내 쓴다. 속도 차이가 매우 크다.

```
CPU가 가상 주소 0x1000에 접근하려 할 때:

1단계: TLB 확인 (매우 빠름, 약 1 클럭)
  → 캐싱되어 있으면 바로 물리 주소 반환 (TLB Hit)
  → 없으면 2단계로

2단계: 페이지 테이블 조회 (느림, 메인 메모리 접근 필요)
  → 물리 주소를 찾아서 반환하고, 결과를 TLB에 저장
```

**PCB(Process Control Block)**: 프로세스의 모든 상태 정보를 저장하는 자료구조이다. CPU 레지스터 값, 프로그램 카운터, 페이지 테이블 포인터, 프로세스 상태 등이 담겨 있다. 컨텍스트 스위칭 시 현재 프로세스의 상태를 PCB에 저장하고, 다음 프로세스의 상태를 PCB에서 불러온다.

**TCB(Thread Control Block)**: 스레드의 상태 정보를 저장하는 자료구조이다. PCB보다 훨씬 가볍다. 스레드는 프로세스의 메모리 공간을 공유하므로, TCB에는 CPU 레지스터, 스택 포인터 등 스레드 고유의 정보만 저장하면 된다.

#### 1.1 프로세스 컨텍스트 스위칭과 가상 메모리(MMU)

프로세스 컨텍스트 스위칭은 MMU에 큰 부담을 준다.

**독립적인 가상 주소 공간**: 각 프로세스는 자신만의 가상 주소 공간과 페이지 테이블을 가진다. CPU는 이 가상 주소를 사용하여 명령어를 실행하고, MMU가 페이지 테이블을 통해 실제 물리 주소로 변환한다.

**컨텍스트 스위칭이 일어나면**:

1. 프로세스 A에서 프로세스 B로 전환될 때, 운영체제는 먼저 프로세스 A의 모든 상태(컨텍스트)를 PCB에 저장한다.
2. 이어서 프로세스 B의 상태를 PCB에서 불러와 CPU 레지스터에 로드한다.
3. 이 과정에서 MMU가 참조하는 **페이지 테이블 포인터가 프로세스 B의 것으로 변경**된다.

여기서 핵심적인 오버헤드가 발생한다. 페이지 테이블이 바뀌면 **TLB에 캐싱되어 있던 내용이 전부 무효화**된다. 프로세스 A의 "가상 주소 → 물리 주소" 캐시는 프로세스 B에서는 완전히 다른 매핑이기 때문이다.

```
프로세스 A 실행 중:
  TLB: [0x1000→0x5A00, 0x2000→0x7B00, ...] ← 캐시가 잘 쌓여 있음 (빠름)

프로세스 B로 전환:
  TLB: [비어 있음] ← 전부 무효화됨 (TLB Flush)
  → 프로세스 B는 모든 주소 변환을 느린 메인 메모리의 페이지 테이블에서 다시 해야 함
  → 시스템 성능 저하
```

> **Python에서 이것이 중요한 이유**: Gunicorn 같은 WSGI 서버가 워커를 프로세스 단위로 띄우는 구조에서는, 워커 간 전환 시 이 프로세스 컨텍스트 스위칭 비용이 발생한다. 워커 수를 CPU 코어 수에 맞추는 이유 중 하나가 바로 이 오버헤드를 최소화하기 위함이다.

#### 1.2 스레드 컨텍스트 스위칭과 가상 메모리(MMU)

스레드 컨텍스트 스위칭은 프로세스 컨텍스트 스위칭보다 훨씬 가볍다.

**공유하는 가상 주소 공간**: 같은 프로세스에 속한 모든 스레드는 동일한 가상 주소 공간을 공유한다. 즉, 모든 스레드가 같은 페이지 테이블을 사용한다.

**컨텍스트 스위칭이 일어나면**:

1. 스레드 A에서 스레드 B로 전환될 때, 운영체제는 스레드 A의 일부 상태(CPU 레지스터, 스택 포인터 등)만 TCB에 저장한다.
2. 이후 스레드 B의 상태를 TCB에서 불러와 로드한다.
3. 이때 **페이지 테이블 포인터는 변경되지 않는다.** 스레드 A와 B가 동일한 가상 주소 공간을 사용하므로, MMU는 기존 TLB 캐시를 그대로 유지할 수 있다.

```
스레드 A 실행 중:
  TLB: [0x1000→0x5A00, 0x2000→0x7B00, ...] ← 캐시가 잘 쌓여 있음

스레드 B로 전환:
  TLB: [0x1000→0x5A00, 0x2000→0x7B00, ...] ← 그대로 유지! (TLB Flush 없음)
  → 성능 저하 거의 없음
```

이 때문에 스레드 컨텍스트 스위칭은 MMU 관련 오버헤드가 발생하지 않아 매우 빠르다.

> **Python에서의 의미**: CPython의 스레드는 OS 네이티브 스레드이므로, 스레드 간 전환 시 이 가벼운 컨텍스트 스위칭이 일어난다. 다만 Python에는 GIL이 있어서, 스레드 전환 시 GIL 획득/해제라는 추가 비용이 존재한다.

***

### 2. Python의 스레드와 운영체제 스레드의 관계

#### 2.1 C 확장과 OS 호출

자바가 네이티브 메서드(JNI)를 통해 OS 기능을 호출하듯, Python(CPython)도 **C로 작성된 내부 코드**를 통해 OS의 스레드 생성 기능을 호출한다.

Python에서 스레드를 생성하면 내부적으로 다음과 같은 일이 발생한다.

python

````python
import threading

t = threading.Thread(target=my_function)
t.start()
```

1. `t.start()`가 호출되면 CPython 내부의 C 코드가 실행된다.
2. 이 C 코드는 OS에 맞는 시스템 콜을 실행한다.
   - Linux: `pthread_create()` 호출
   - Windows: `CreateThread()` 호출
3. OS가 실제 네이티브 스레드를 생성하고, CPython은 이 네이티브 스레드와 Python의 `Thread` 객체를 연결한다.

자바의 구조와 비교하면 이렇다.

| | Java | Python (CPython) |
|---|---|---|
| 스레드 생성 코드 | `thread.start()` | `thread.start()` |
| 내부 호출 | `start0()` (native method, JNI) | C 함수 (CPython 내부) |
| OS 호출 | `pthread_create()` 등 | `pthread_create()` 등 |
| 결과 | Java Thread ↔ OS Thread 매핑 | Python Thread ↔ OS Thread 매핑 |

구조적으로 매우 유사하다. 차이점은 자바는 JNI라는 명시적인 인터페이스를 통해 네이티브 코드를 호출하는 반면, CPython은 인터프리터 자체가 C로 작성되어 있으므로 별도의 인터페이스 없이 직접 OS 함수를 호출한다는 점이다.

### 2.2 레벨별 스레드 정리

스레드는 동작하는 레벨에 따라 세 가지로 구분된다.

**하드웨어 스레드**

코어의 연산 속도는 메모리보다 빠르기 때문에, 메모리에서 데이터를 보내는 시간을 기다리는 것은 낭비이다. 이 대기 시간 동안 다른 스레드의 작업을 수행할 수 있도록 한 것이 하드웨어 스레드이다. 인텔의 하이퍼스레딩(Hyper-Threading)이 대표적인 예로, 물리적 코어 하나가 논리적으로 두 개의 스레드를 처리한다. 싱글 코어 CPU에 하드웨어 스레드가 두 개라면, OS는 이를 듀얼 코어로 인식하고 그에 맞춰 스케줄링한다.

**커널 레벨 스레드 (네이티브 스레드)**

OS 커널이 직접 생성하고 관리하는 스레드이다. 커널 스레드의 컨텍스트 스위칭에는 커널이 개입하므로 비용이 발생한다.

**유저 레벨 스레드**

스레드 개념을 프로그래밍 언어 레벨에서 추상화한 것이다. Python에서 `threading.Thread`로 생성하는 것이 유저 레벨 스레드에 해당한다. 유저 레벨 스레드가 실제로 CPU에서 실행되려면 반드시 커널 레벨 스레드와 연결되어야 한다.
```
[유저 레벨]     Python Thread 객체, asyncio 코루틴
                        ↓ (매핑)
[커널 레벨]     OS 네이티브 스레드 (pthread 등)
                        ↓ (스케줄링)
[하드웨어]      CPU 코어의 하드웨어 스레드
```

### 2.3 매핑 모델: 1:1, M:1, M:N

유저 레벨 스레드를 커널 레벨 스레드와 어떻게 연결하느냐에 따라 세 가지 모델로 나뉜다.

**1:1 모델 — CPython의 현재 방식**

유저 레벨 스레드 하나가 커널 레벨 스레드 하나와 직접 연결되는 방식이다. CPython의 `threading` 모듈이 이 방식을 사용한다.
```
Python Thread 1  ↔  OS Thread 1  →  코어 1
Python Thread 2  ↔  OS Thread 2  →  코어 2
Python Thread 3  ↔  OS Thread 3  →  코어 3
```

장점:
- OS가 각 스레드를 서로 다른 코어에 할당할 수 있어 **I/O 바운드 작업에서 병렬성 확보**에 유리하다.
- 하나의 스레드가 I/O로 블로킹되어도 다른 스레드는 OS 스케줄러에 의해 계속 실행된다.

단점:
- Python 스레드를 만드는 것이 곧 OS 스레드를 만드는 것이므로 생성 비용이 비싸다.
- OS가 관리할 수 있는 네이티브 스레드 수에 한계가 있다.
- **CPython 고유의 제약**: GIL 때문에 OS 스레드를 여러 개 만들어도 CPU 바운드 작업에서는 진짜 병렬 실행이 되지 않는다. 이 점이 Java의 1:1 모델과의 가장 큰 차이이다.

> **Java와의 핵심 차이**: Java의 1:1 모델에서는 스레드 4개가 CPU 코어 4개에서 진짜로 동시에 실행될 수 있다. 하지만 CPython에서는 GIL 때문에 Python 바이트코드를 실행하는 스레드는 항상 1개뿐이다. 같은 1:1 모델이지만 GIL로 인해 실질적인 동작이 다르다.

**M:1 모델**

여러 유저 레벨 스레드가 하나의 커널 레벨 스레드에 연결되는 방식이다.
```
Python Thread 1  ─┐
Python Thread 2  ─┼→  OS Thread 1  →  코어 1
Python Thread 3  ─┘
```

장점:
- 유저 레벨 스레드 간 컨텍스트 스위칭이 가볍다.
- 커널 레벨 스레드가 1개이므로 공유 자원에 대한 Race Condition 위험이 줄어든다.

단점:
- 멀티 코어를 활용하지 못한다.
- 하나의 유저 레벨 스레드에서 Blocking I/O가 발생하면 커널 스레드 자체가 블로킹되어 모든 유저 레벨 스레드가 멈춘다.

CPython은 이 모델을 사용하지 않는다. 다만 GIL의 존재로 인해 CPU 바운드 작업에서는 사실상 M:1처럼 동작한다는 점이 흥미롭다. 물론 I/O 바운드에서는 GIL이 해제되므로 진짜 M:1과는 다르다.

**M:N 모델 — asyncio의 동작 방식**

M개의 유저 레벨 스레드(혹은 경량 태스크)를 N개의 커널 레벨 스레드에 할당하는 방식이다. 보통 M이 N보다 훨씬 크다.
```
코루틴 1  ─┐
코루틴 2  ─┤
코루틴 3  ─┼→  이벤트 루프 (OS Thread 1)  →  코어 1
코루틴 4  ─┤
코루틴 5  ─┘
````

장점:

* 유저 레벨 태스크의 생성과 전환이 매우 빠르고 가볍다.
* OS의 제한 없이 수만\~수십만 개의 동시 태스크를 생성할 수 있다.

단점:

* 스케줄링 로직을 런타임(이벤트 루프)이 직접 관리해야 하므로 구현이 복잡하다.

Python의 `asyncio`가 이 모델에 해당한다. 수만 개의 코루틴이 소수의 OS 스레드(기본적으로 1개의 이벤트 루프 스레드) 위에서 실행된다.

***

### 3. Python은 동시성 문제를 어떻게 풀어왔는가

#### 3.1 GIL의 제약 (기존의 한계)

CPython의 `threading` 모듈은 1:1 모델로 OS 네이티브 스레드를 생성하지만, GIL 때문에 CPU 바운드 작업에서는 진짜 병렬 실행이 되지 않는다. I/O 바운드에서는 GIL이 해제되어 스레드가 효과적이지만, 수만 개의 동시 연결을 처리해야 하는 경우 OS 스레드를 그만큼 만드는 것은 비현실적이다.

#### 3.2 multiprocessing — 프로세스로 GIL 우회

CPU 바운드 작업의 병렬 처리를 위해 `multiprocessing` 모듈을 사용한다. 프로세스마다 독립된 GIL을 가지므로 진짜 병렬 실행이 가능하다.

python

```python
from multiprocessing import Pool

def heavy_task(n):
    return sum(i * i for i in range(n))

# 프로세스 4개로 병렬 처리
with Pool(4) as pool:
    results = pool.map(heavy_task, [10_000_000] * 4)
```

다만 프로세스 간 메모리가 독립적이므로, 데이터를 주고받으려면 IPC(Inter-Process Communication) 오버헤드가 발생하고 메모리 사용량도 증가한다. 1장에서 다룬 프로세스 컨텍스트 스위칭의 TLB 무효화 비용도 존재한다.

#### 3.3 asyncio — 코루틴으로 대량 동시 처리

대량의 I/O 바운드 동시 처리를 위해 Python 3.4부터 `asyncio`가 도입되었다. asyncio의 코루틴은 OS 스레드가 아니라 **이벤트 루프가 관리하는 경량 태스크**이다.

python

```python
import asyncio

async def fetch_data(url):
    # I/O 대기 중 이벤트 루프가 다른 코루틴을 실행
    await some_async_http_call(url)

async def main():
    # 10,000개의 코루틴을 동시에 실행 — OS 스레드는 1개뿐
    tasks = [fetch_data(f"https://api.example.com/{i}") for i in range(10_000)]
    await asyncio.gather(*tasks)

asyncio.run(main())
```

코루틴의 핵심은 **블로킹 작업을 만나면 자발적으로 제어권을 이벤트 루프에 돌려준다**는 것이다.

1. 코루틴 A가 이벤트 루프 위에서 실행되다가 DB 조회(`await`)를 만난다.
2. 이벤트 루프는 코루틴 A의 상태를 메모리에 저장하고 일시 중단한다.
3. 이벤트 루프는 즉시 대기 중이던 코루틴 B를 가져와 실행한다.
4. DB 조회가 완료되면 코루틴 A는 다시 실행 가능 상태가 되어 이벤트 루프에 의해 재개된다.

이 구조 덕분에 OS 스레드 1개로도 수만 개의 동시 I/O 작업을 처리할 수 있다.

#### 3.4 Java의 가상 스레드와 Python asyncio 비교

Java 21의 가상 스레드와 Python의 asyncio는 같은 문제(대량의 동시 I/O 처리)를 풀지만, 접근 방식이 다르다.

|          | Java 가상 스레드                 | Python asyncio                     |
| -------- | --------------------------- | ---------------------------------- |
| 매핑 모델    | M:N (가상 스레드 : 캐리어 스레드)      | M:N (코루틴 : 이벤트 루프 스레드)             |
| 코드 스타일   | **동기 코드 그대로** 사용            | `async/await` 키워드 필요               |
| 블로킹 처리   | JVM이 자동으로 감지하여 캐리어 스레드에서 분리 | 개발자가 `await`으로 명시적으로 양보            |
| 기존 코드 호환 | 기존 동기 코드 거의 그대로 사용 가능       | 비동기 전용 라이브러리 필요                    |
| 생태계      | 기존 라이브러리 대부분 호환             | `aiohttp`, `asyncpg` 등 별도 라이브러리 필요 |

**Java 가상 스레드의 가장 큰 장점**은 기존 동기 코드를 거의 수정하지 않고도 비동기의 효율을 얻을 수 있다는 점이다. JVM이 블로킹 I/O를 자동으로 감지하여 캐리어 스레드에서 가상 스레드를 분리해준다.

반면 **Python asyncio**는 `async/await` 키워드를 사용해야 하고, 기존 동기 라이브러리(`requests`, `psycopg2` 등)를 비동기 대응 라이브러리(`aiohttp`, `asyncpg` 등)로 교체해야 한다. 코드 변경이 더 크지만, `await` 지점이 명시적이므로 제어 흐름을 파악하기 쉽다는 장점도 있다.

python

```python
# Python — async/await이 필요
async def get_user(user_id):
    user = await db.fetch_one("SELECT * FROM users WHERE id = $1", user_id)  # 명시적 양보
    return user
```

java

````java
// Java 가상 스레드 — 동기 코드 그대로
User getUser(int userId) {
    User user = db.query("SELECT * FROM users WHERE id = ?", userId);  // JVM이 자동 처리
    return user;
}
```

> **asyncio 사용 시 주의점**: 코루틴 안에서 동기 블로킹 호출(예: `requests.get()`, `time.sleep()`)을 하면 이벤트 루프 전체가 멈춘다. 반드시 비동기 대응 라이브러리를 사용하거나, `asyncio.to_thread()`로 동기 코드를 별도 스레드에서 실행해야 한다. 이는 Java 가상 스레드에서 `synchronized` 블록 내 I/O로 Pinned가 발생하는 것과 유사한 함정이다.

### 3.5 Free-threading (PEP 703) — Python의 미래

Python 3.13부터 실험적으로 도입된 Free-threading은 GIL을 완전히 제거하는 시도이다. 이것이 안정화되면 Python의 `threading` 모듈도 Java처럼 진짜 병렬 실행이 가능해진다.
```
현재 CPython (GIL 있음):
  Thread 1: [실행] → 대기 → [실행] → ...
  Thread 2: 대기 → [실행] → 대기 → ...
  → 동시에 Python 코드를 실행하는 건 항상 1개

Free-threading (GIL 없음):
  Thread 1: [실행] [실행] [실행] → 코어 1
  Thread 2: [실행] [실행] [실행] → 코어 2
  → Java처럼 진짜 병렬 실행 가능
````

이것이 실현되면, Python은 CPU 바운드 작업에서도 멀티스레드로 성능을 낼 수 있게 되어 `multiprocessing`의 IPC 오버헤드와 메모리 중복 문제를 피할 수 있다. 다만 현재는 실험적 단계이며, 기존 C 확장 라이브러리들의 스레드 안전성 확보가 선행되어야 하므로 점진적으로 진행되고 있다.

***

### 4. Python 동시성 모델 종합 정리

| 방식             | 모듈                  | 매핑 모델         | 적합한 작업       | GIL 영향         |
| -------------- | ------------------- | ------------- | ------------ | -------------- |
| 멀티스레드          | `threading`         | 1:1           | I/O 바운드      | 받음 (I/O 시 해제)  |
| 멀티프로세스         | `multiprocessing`   | 프로세스 분리       | CPU 바운드      | 없음 (프로세스별 GIL) |
| 비동기            | `asyncio`           | M:N (코루틴:스레드) | 대량 I/O 동시 처리 | 거의 없음          |
| Free-threading | `threading` (3.13+) | 1:1 (GIL 없음)  | CPU + I/O 모두 | 없음 (실험적)       |

실무에서의 선택 기준은 명확하다.

* **웹 서버에서 일반적인 요청 처리**: Gunicorn(멀티프로세스) 또는 Uvicorn(asyncio) 사용
* **DB 조회, API 호출 등 I/O가 많은 경우**: `asyncio` 또는 `threading`
* **이미지 처리, 수학 연산 등 CPU 집약적 작업**: `multiprocessing`
* **대량의 동시 연결 (수천\~수만)**: `asyncio` 기반의 ASGI 서버(Uvicorn 등)

***

### 마치며

프로세스와 스레드의 컨텍스트 스위칭은 언어에 관계없이 동일한 OS 수준의 동작이다. 하지만 그 위에서 각 언어가 스레드를 어떻게 활용하느냐는 크게 다르다. Java는 1:1 모델에서 출발하여 가상 스레드(M:N)로 진화했고, Python은 GIL이라는 고유한 제약 때문에 일찍이 `multiprocessing`과 `asyncio`라는 우회 경로를 발전시켜 왔다. 그리고 Free-threading이라는 근본적인 해결책이 실험되고 있는 지금, Python의 동시성 모델은 또 한 번의 전환점을 앞두고 있다.
