# chapter 3. OpenAI API, LangChain, LlamaIndex

## 3.1 OpenAI API 란 무엇인가?&#x20;

### OpenAI 라는 회사에 대해 이야기하다&#x20;

OpenAI 의 핵심 목표는 대형 기술 회사들과의 독립적인 오픈 소스 인공지능 조직을 만들어 안전하고 포괄적인 인공지능의 발전을 촉진하는 것이다. 이 비영리 조직의 초기 버전은 '친근한 인공지능'을 발전시키는 것이었으며, 이는 인공지능 기술의 발전을 통해 인류 전체에게 이익을 주고 잠재적인 위험을 방지하기 위한 것이었다.&#x20;

OpenAI 이사회는 'OpenAI 의 모든 활동을 총괄하는 관리 기관' 으로서 로마의 원로원과 비슷한 역할을 하고 있다.&#x20;

이후 흐름은 모두가 알고 있듯이, OpenAI 의 LLM 들은 자연어 이해와 생성 측면에서 엄청난 발전을 이루었다.(\~ing)&#x20;

...

## 3.2 LangChain 이란 무엇인가?&#x20;

### LangChain 에 대해 이야기하다

랭체인은 LLM 을 외부 데이터와 연결하여 개발자가 더 빠르고 쉽게 언어 기반의 인공지능 애플리케이션을 구축할 수 있게 도와주는 오픈 소스 기반 체계이다.&#x20;

#### 1. LangChain 개발 환경 개요

랭체인의 전체 기반 체계는 파이썬과 자바스크립트 라이브러리를 비롯한 다양한 구성 요소와 통합 인터페이스를 포함하고 있으며, 이러한 구성 요소를 연결하여 체이닝과 에이전트 실행환경을 구성한다. 또한 쉽게 배포할 수 있는 참조 애플리케이션 템플릿과 랭체인을 REST API 로 배포할 수 있는 LangServe 배포 플랫폼도 제공하고 있다. 게다가 랭체인 생태계에서는 LangSmith 라는 플랫폼도 포함되어 있는데, 이는 어떤 LLM 기반 체계라도 체이닝을 디버깅, 테스트, 평가, 모니터링할 수 있는 도구이다. 이 구성 요소들과 플랫폼이 통합되어 개발, 제품화, 배포를 아우르는 LLM 애플리케이션 수명 주기 전체에 걸친 모든 요구를 충족시키고 있다.&#x20;

#### 2. LangChain 기반 인공지능 애플리케이션 개발의 3가지 장점&#x20;

첫째, 랭체인은 유연한 기반 체계로서 여러 LLM 과 상호작용할 수 있는 기능을 제공한다. 물론 처음에는 주로 OpenAI 모델을 지원하는 것으로 시작했지만, 유연한 설계 덕에 여러 종류의 다양한 모델을 지원하기 때문에, 특정 모델에 얽매일 필요 없이 자신이 개발하는 애플리케이션에 가장 적합한 모델을 선택해 통합하고 사용할 수 있다.&#x20;

둘째, 랭체인은 LLM 애플리케이션 개발에서 필요로 하는 다양한 기술적 세부사항을 캡슐화하여 많은 작업을 간소화해준다. 랭체인이 포함하고 있는 작업에는 프롬프트 템플릿, 프롬프트 관리, 다양한 유형의 대형 모델과 상호작용하는 공통 인터페이스, ReAct 와 같은 언어적 논리 사고 기반 체계 코드 구현, 외부 데이터 소스와의 상호작용, 상호작용형 에이전트 생성, 등등 이 있다.&#x20;

* 예를 들어, `create_react_agent` 함수를 호출하는 것만으로도 ReAct 사고 기반 체계를 갖춘 에이전트를 생성하고 쉽게 ReAct 의 추론 기능을 구현할 수 있다. 이 모든 세부사항을 우리가 직접 구현할 필요 없이 LangChain 의 API 에 캡슐화되어 있는 것을 사용하기만 하면 된다.

마지막으로, 랭체인은 다양한 타사 애플리케이션과의 인터페이스를 완벽하게 구축하고 있으며, 여러 종류의 인공지능 개발 관련 라이브러리 및 도구와 통합되어 있다.&#x20;

* 예를 들어, 랭체인은 여러 종류의 백터 데이버베이스와 상호작용하는 인터페이스를 포함하고 있다.&#x20;

#### 3. LangChain 기반 인공지능 애플리케이션 개발 시 주의사항

첫째, 랭체인은 다양한 기능, 도구, 타사 인터페이스를 제공하므로 기능과 생태계가 다소 복잡하게 느껴질 수 있고, 이는 LLM 개발에 익숙하지 않은 초보자들에게는 큰 도전 과제일 수 있다.&#x20;

둘째, 랭체인을 통해 복잡한 애플리케이션을 개발할 경우, 지나치게 많은 데이터를 하게 되면 성능 문제가 발생할 수 있다.&#x20;

마지막으로, 랭체인은 빠르게 발전하고 있으며, 그에 따라 버전 갱신 속도가 매우 빠르기 때문에, 이전 버전의 코드가 부지불식 간에 새 버전에서 정상적으로 동작하지 않을 수 있다.&#x20;

따라서 랭체인의 장점과 잠재적인 문제를 고려하려, 랭체인 대신 OpenAI 의 API 를 통해 GPT 기반의 에이전트를 개발하기로 결정했다면 그것도 나름 현명한 선택일 수 있다.&#x20;

### LangChain 의 여섯 가지 모듈&#x20;

랭체인은 LLM 기반 애플리케이션을 구축할 수 있는 오픈 소스 도구 모음이다. 이 도구는 여섯 가지 주요 모듈로 구성되어 있다.&#x20;

여섯 가지 모듈 각각에 대한 설명은 다음과 같다.&#x20;

* 모델 입출력 : 이 모듈은 랭체인과 LLM 사이의 인터페이스 역할을 하며, 프롬프트 템플릿 생성을 포함한 입력 처리와 출력 데이터 형식의 파싱을 포함한 출력 처리, 다양한 LLM 과의 상호작용을 담당한다.&#x20;
* 검색 : 이 모듈은 프로그램에서 특정 데이터와 상호작용할 수 있도록 도와준다. 랭체인이 데이터베이스, 파일 시스템, 다른 온라인 자원과 같은 외부 데이터 소스에서 필요한 정보를 검색할 수 있도록 해준다.&#x20;
* 연쇄(chain) : 이 모듈은 복잡한 논리와 기능을 구축하기 위해 사용되는 일반적인 구성 요소를 포함하고 있다. 체이닝은 랭체인이 정보를 처리하고 작업을 수행하는 기본적인 구성 요소이다.&#x20;
* 에이전트 : 랭체인은 이 모듈을 통해 고수준의 지시에 따라 어떤 도구를 사용할지 선택할 수 있다. 에이전트는 주어진 상황에서 가장 효율적인 작업 방식을 결정하는 역할을 한다.&#x20;
* 기억 : 기억 모듈은 체이닝이 실행되는 동안 프로그램의 상태를 유지한다. 랭체인은 이를 통해 이전의 컨텍스트를 기억하고 여러 차례의 실행에 연속성을 제공할 수 있다.
* 콜백 : 이 모듈은 체이닝의 중간 단계를 기록하고 전송하는 역할을 한다. 이를 통해 개발자는 랭체인의 실행 상태를 모니터링 하고 분석하여 성능과 기능을 최적화할 수 있다.&#x20;

이 여섯가지 중 가장 중요한 것은 모델 입출력, 검색, 에이전트, 연쇄 이렇게 네 가지이며, 기억과 콜백은 부가적인 모듈로 본다.&#x20;

### LangChain 과 에이전트 개발&#x20;

랭체인은 LLM 을 다른 데이터나 계산 소스에 연결할 수 있는 다양한 도구를 제공한다. 여기에는 검색엔진, API, 기타 데이터 저장소가 포함된다. LLM 은 학습한 내용만 알고 있기 때문에, 이 지식은 빠르게 도태될 수 있으며, 이러한 한계를 극복하기 위해 도구를 사용하여 최신 데이터를 가져와 프롬프트에 컨텍스트를 삽입할 수 있다. 도구는 이 외에도 코드 실행, 파일 수정과 같은 행동도 할 수 있으며, LLM 은 이러한 행동의 결과를 관찰하여 다음에 무엇을 할 지 결정한다.&#x20;

랭체인의 기억 모듈은 에이전트가 이전의 컨텍스트를 기억하는 데 도움을 준다.&#x20;

기억은 최근 다섯 번에 걸친 도구 사용 과정 목록과 같은 단기 기억이 될 수도 있고, 과거와 현재 상황이 가장 유사한 도구 사용 과정의 기억과 같은 장기 기억이 될수도 있다.

랭체인은 에이전트 executor 를 통해 에이전트의 논리를 실행하고, 특정 기준이 충족되면 실행을 멈춘다.&#x20;

여기서 주목할 점은 LLM 애플리케이션 구축 과정에서 랭체인의 여섯 가지 모듈은 매우 느슨하게 결합되어 있다는 것이다. 각 모듈에는 정해진 호출 순서나 고정된 인터페이스가 존재하지 않는다. 따라서 개발자는 자유롭게 모듈을 설계하고 조합할 수 있다.&#x20;

## 3.3 LlamaIndex 란 무엇인가?&#x20;

LLM 애플리케이션 개발 분야에 랭체인만 있는 것은 아니다. 라마인덱스는 호평을 받은 또 다른 오픈 소스 LLM 애플리케이션 개발 기반 체계이다.&#x20;

### LlamaIndex 에 대해 이야기하다&#x20;

라마인덱스 전략은 랭체인과 약간 다르다. 라마인덱스는 인공지능 기반 RAG 와 멀티네넌트 RAG 시스템 구축에 특히 주력하고 있다. 라마인덱스 기반의 기업 솔루션은 기술과 보안 장벽을 제거하고 기업의 데이터 활용과 서비스 역량을 강화하는데 중점을 두고 있다.&#x20;

또 한가지 언급할 점은 라마인덱스가 문서의 구조와 실행 가능성 측면에서 랭체인보다 훨씬 낫다는 것이다. 물론 이는 랭체인이 너무 방대하고 전면적으로 확장되다 보니 그 여파로 오히려 방향을 잡기 어려워진 것도 이유일 수 있다. 따라서 문서 검색과 RAG 에만 집중하고자 한다면 '작고 아름다운' 라마인덱스를 선택하는 것이 더 나은 선택일 수 있다.&#x20;

### LlamaIndex 와 RAG 기반 인공지능 개발&#x20;

대규모 언어 모델(LLM)이 답변을 생성하기 전, 외부의 신뢰할 수 있는 지식 베이스에서 관련 정보를 검색하여 활용하는 기술이다.&#x20;

에이전트와 마찬가지로 RAG 도 풍부한 실무 응용 사례를 보유하고 있다. 물론 RAG 로 생성된 인공지능 애플리케이션 자체가 하나의 에이전트에 해당할 수 있고, RAG 를 에이전트 구축 과정의 핵심 기술로 사용할 수도 있다.&#x20;

라마인덱스의 도구를 좀 더 구체적으로 나열하면 다음과 같다.&#x20;

* data connector : 데이터를 수집한다. 데이터는 API, PDF, SQL 등 다양한 형태일 수 있으며, 라마인덱스는 이에 맞는 읽기 인터페이스를 제공한다.&#x20;
* data index : 데이터를 LLM 이 이해하기 쉬운 vector 와 같은 중간 표현 형태로 index 하여 구조화한다.&#x20;
* engine : 데이터를 자연어로 접근할 수 있도록 한다.&#x20;
  * 예를 들어, 요청 엔진은 지식을 강화한 출력을 위한 강력한 검색 인터페이스&#x20;
  * 대화 엔진은 데이터를 바탕으로 다중 메시지 '상호작용'을 지원하는 대화형 인터페이스이다.&#x20;
  * 데이터 에이전트는 LLM 이 구동하는 knowledge worker 로, 간단한 지원부터 API 통합까지 다양한 기능을 수행할 수 있다.&#x20;
* application integration : 라마인덱스를 다른 생태계와 통합한다.&#x20;

아래는 에이전트가 라마인덱스에서 LLM 을 통해 RAG 를 구현하는 과정을 보여준다.&#x20;

1. 사용자의 요청 입력 : 사용자가 시스템에 질문이나 부탁을 포함한 요청을 입력한다.&#x20;
2. 에이전트가 관련 정보 검색 : 에이전트는 사용자의 요청에 따라 관련 정보를 검색하는데, 이 과정에서 인터넷이나 특정 데이터베이스를 참고해 관련 문서나 데이터를 찾는다. 일반적으로 기업 내부 정보는 백터 데이터베이스에 저장된다.&#x20;
3. 정보 검색 : 검색 결과에서 구체적인 정보를 추출하여, 이를 사용자 요청에 응답할 상황 정보로 사용한다.&#x20;
4. LLM 에 관련 정보 전달 : 에이전트는 검색된 정보와 사용자의 최초 요청을 묶어 LLM 에 전달한다.&#x20;
5. LLM 이 응답 생성 : LLM 은 이러한 정보를 사용하여 풍부하고 정보성 있는 답변을 생성한다.&#x20;
6. 사용자의 요청에 응답 : 마지막으로, 랭체인 에이전트는 LLM 이 생성한 답변을 사용자에게 제공하는데, 이 답변은 사용자의 원래 요청과 관련된 데이터 출처에서 검색한 정보를 바탕으로 생성한 것이다.&#x20;

이 과정은 여러번 반복할 수 있으며, 사용자의 요청은 후속 상호작용을 개선할 때 유용할 수 있다. 추가 정보가 필요하거나 사용자가 추가 질문을 하면, 시스템은 추가 요청을 유도할 수 있으며, 이전 답변에서 얻은 정보를 사용하여 새로운 요청의 컨텍스트를 더 풍부하게 만들 수 있다.&#x20;

라마인덱스를 이용한 RAG 에이전트 구축은 매우 간단하다.&#x20;

**하지만 단순한 RAG 에이전트 구축이 아닌, 배포(LangServe) / 디버깅 & 모니터링(LangSmith) 와 같이 라이프사이클을 생각한다면 랭체인이 좋은 선택이다.**
